{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexperto.co scraping\n",
    "## Made by David Bautista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import textract\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run if you want to extract taxonomy from one single pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anexando texto de anti_pdf_1.pdf\n",
      "tesseract de  anti_pdf_2.pdf\n",
      "no se pudo anexar texto de anti_pdf_2.pdf can only concatenate str (not \"bytes\") to str\n",
      "anexando texto de anti_pdf_3.pdf\n",
      "anexando texto de anti_pdf_4.pdf\n"
     ]
    }
   ],
   "source": [
    "filenames = [\"anti_pdf_2.pdf\"]\n",
    "text_2 = \"\"\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "    try:\n",
    "        pdfFileObj = open(filename,'rb')               #open allows you to read the file\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)   #The pdfReader variable is a readable object that will be parsed\n",
    "        num_pages = pdfReader.numPages                 #discerning the number of pages will allow us to parse through all the pages\n",
    "\n",
    "        count = 0\n",
    "        text_i = \"\"\n",
    "        while count < num_pages:                       #The while loop will read each page\n",
    "            pageObj = pdfReader.getPage(count)\n",
    "            count +=1\n",
    "            text_i += pageObj.extractText()\n",
    "\n",
    "        #Below if statement exists to check if the above library returned #words. It's done because PyPDF2 cannot read scanned files.\n",
    "\n",
    "        if text_i != \"\":\n",
    "            print(\"anexando texto de\", filename)\n",
    "            text += text_i\n",
    "\n",
    "        #If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text\n",
    "\n",
    "        else:\n",
    "            print(\"tesseract de \", filename)\n",
    "            #text += textract.process(filename, method='tesseract', language='spa')\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"no se pudo anexar texto de\", filename, error)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run if you wanna extract taxonomy from multiple texts in a folder :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"HistoriasHotLibro/\"\n",
    "ext = 'txt'\n",
    "files = [f for f in listdir(directory_path) if isfile(join(directory_path, f)) and '.{}'.format(ext) in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for file_name in files:\n",
    "    file = open(join(directory_path, file_name), 'r')\n",
    "    file_text = file.read()\n",
    "    text += re.sub(u'\\n', ' ', unidecode.unidecode(file_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text normalization ðŸ¤“ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1789862"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: \n",
    "    text_dc = text.decode().lower()\n",
    "    text_dc = \" \".join(text_dc.split())\n",
    "    text_dc = re.sub(u'\\n', ' ', unidecode.unidecode(text_dc))\n",
    "    text_dc = \" \".join([word for word in re.findall(r'[a-zA-Z]\\w+',text_dc) if len(str(word)) > 3 and len(str(word)) < 16])\n",
    "except:\n",
    "    text_dc = \" \".join(text.split())\n",
    "    text_dc = re.sub(u'\\n', ' ', unidecode.unidecode(text_dc))\n",
    "    text_dc = \" \".join([word for word in re.findall(r'[a-zA-Z]\\w+',text_dc) if len(str(word)) > 3 and len(str(word)) < 16])\n",
    "len(text_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run its just a tweet for example\n",
    "text_dc = 'Les decimos Chau a los lÃ­mites... las mujeres de estos tiempos avanzamos, en la vida, en lo profesional, en las elecciones sexuales...por eso desterramos los lÃ­mites...! No debemos perder de vista, en este contexto:\\nâš  la #prevenciÃ³nes esðŸ‘‰ INDISPENSABLE.\\nEn otros posts anteriores decia #ocupate, no te preocupes!\\ny de eso se trata.\\nÂ¿Por que? La visita anual ginecolÃ³gica es importanteâ°\\nÂ¿Que favorece?ðŸ¤”â€¼ âœ”-Prevenir y detectar alteraciones del aparato reproductor.\\n-Detectar de forma precoz el cÃ¡ncer genital y el cÃ¡ncer de mama.\\nâœ”-Aclarar dudas sobre anticoncepciÃ³n, planificaciÃ³n familiar, cuidados y hÃ¡bitos higiÃ©nicos del aparato reproductor.\\nâœ”-Permiten detectar patologÃ­a que todavÃ­a no ha provocado sÃ­ntomas asintomÃ¡tica.\\nâœ”-El cÃ¡ncer de cuello de Ãºtero y el cÃ¡ncer de mama constituyen una de las principales causa de muerte en la mujer. Ambos Ã³rganos son de fÃ¡cil acceso para su estudio, a fin de detectar lesiones iniciales o mÃ¡s aÃºn, lesiones previas al desarrollo del cÃ¡ncer.\\nâœ”-Mantener la fertilidad, si es de tu interÃ©s y evitar las infecciones de transmisiÃ³n sexual.\\nðŸ’ŸEstas son algunas de las razones...Â¿Les parece poco?\\nRecomiendo: la visita ginecolÃ³gica anual.\\nTodos estos temas, entre otros con la detecciÃ³n a tiempo pueden cambiar sus resultados!âœ” No dudes en consultar!\\nðŸŒ¸Dra. Claudia Rey.\\nDirectora MÃ©dica.\\n\"Orgullosa de cuidar la salud de la mujer en cada etapa de su vida\"  ATENCIÃ“N MÃ‰DICA en GINECOLOGÃA - Modalidad Virtual. \\nPara solicitar Turno, para realizar una CONSULTA MÃ‰DICA VIRTUAL, y SOLICITUD de RECETAS: \\nEnviar un mensaje al sgte. NÃºmero: (+54911) 3948-8901\\nÃšnicamente de LUNES a VIERNES, de 10.30 a 17 Hs. ... #pastilladeldiadespues #lapastilla #preservativo #aborto\\n#diud #diu #mirena #anticonceptivos #anticoncepcion #prevenciÃ³n #ginecologia #control\\n#comomecuido #ginecoysalud #ginecosalud'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing without nlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Irene',\n",
       " 'Isabel',\n",
       " 'Navarro',\n",
       " 'Gonzalez',\n",
       " 'Jorge',\n",
       " 'Eduardo',\n",
       " 'Aguilar',\n",
       " 'Rosas',\n",
       " 'Miguel',\n",
       " 'Arturo',\n",
       " 'Barreiro',\n",
       " 'Gonzalez',\n",
       " 'Sinaloa',\n",
       " 'Instituto',\n",
       " 'Tecnologico',\n",
       " 'Culiacan',\n",
       " 'Ciencias',\n",
       " 'Basicas',\n",
       " 'Cecilia',\n",
       " 'Norzagaray',\n",
       " 'GamezInstituto',\n",
       " 'Tecnologico',\n",
       " 'Ciencias',\n",
       " 'BasicasJesus',\n",
       " 'Alberto',\n",
       " 'Baez',\n",
       " 'Torres',\n",
       " 'Introduccion',\n",
       " 'estadistica',\n",
       " 'analisis',\n",
       " 'datos',\n",
       " 'Panorama',\n",
       " 'general',\n",
       " 'inferencia',\n",
       " 'estadistica',\n",
       " 'muestras',\n",
       " 'poblaciones',\n",
       " 'papel',\n",
       " 'probabilidad',\n",
       " 'Procedimientos',\n",
       " 'muestreo',\n",
       " 'recoleccion',\n",
       " 'datos',\n",
       " 'Medidas',\n",
       " 'localizacion',\n",
       " 'media',\n",
       " 'mediana',\n",
       " 'muestra',\n",
       " 'Ejercicios',\n",
       " 'Medidas',\n",
       " 'variabilidad',\n",
       " 'Ejercicios',\n",
       " 'Datos',\n",
       " 'discretos',\n",
       " 'continuos',\n",
       " 'Tipos',\n",
       " 'generales',\n",
       " 'estudios',\n",
       " 'estadisticos',\n",
       " 'diseno',\n",
       " 'experimental',\n",
       " 'estudio',\n",
       " 'observacional',\n",
       " 'estudio',\n",
       " 'retrospectivo',\n",
       " 'Ejercicios',\n",
       " 'Probabilidad',\n",
       " 'Espacio',\n",
       " 'muestral',\n",
       " 'Eventos',\n",
       " 'Ejercicios',\n",
       " 'Conteo',\n",
       " 'puntos',\n",
       " 'muestrales',\n",
       " 'Ejercicios',\n",
       " 'Probabilidad',\n",
       " 'evento',\n",
       " 'Reglas',\n",
       " 'aditivas',\n",
       " 'Ejercicios',\n",
       " 'Probabilidad',\n",
       " 'condicional',\n",
       " 'independencia',\n",
       " 'regla',\n",
       " 'producto',\n",
       " 'Ejercicios',\n",
       " 'Regla',\n",
       " 'Bayes',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'viii',\n",
       " 'Contenido2',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Variables',\n",
       " 'aleatorias',\n",
       " 'distribuciones',\n",
       " 'probabilidad',\n",
       " 'Concepto',\n",
       " 'variable',\n",
       " 'aleatoria',\n",
       " 'Distribuciones',\n",
       " 'discretas',\n",
       " 'probabilidad',\n",
       " 'Distribuciones',\n",
       " 'probabilidad',\n",
       " 'continua',\n",
       " 'Ejercicios',\n",
       " 'Distribuciones',\n",
       " 'probabilidad',\n",
       " 'conjunta',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Esperanza',\n",
       " 'matematica',\n",
       " 'Media',\n",
       " 'variable',\n",
       " 'aleatoria',\n",
       " 'Ejercicios',\n",
       " 'Varianza',\n",
       " 'covarianza',\n",
       " 'variables',\n",
       " 'aleatorias',\n",
       " 'Ejercicios',\n",
       " 'Medias',\n",
       " 'varianzas',\n",
       " 'combinaciones',\n",
       " 'lineales',\n",
       " 'variables',\n",
       " 'aleatorias',\n",
       " 'Teorema',\n",
       " 'Chebyshev',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Algunas',\n",
       " 'distribuciones',\n",
       " 'probabilidad',\n",
       " 'discreta',\n",
       " 'Introduccion',\n",
       " 'motivacion',\n",
       " 'Distribuciones',\n",
       " 'binomial',\n",
       " 'multinomial',\n",
       " 'Ejercicios',\n",
       " 'Distribucion',\n",
       " 'hipergeometrica',\n",
       " 'Ejercicios',\n",
       " 'Distribuciones',\n",
       " 'binomial',\n",
       " 'negativa',\n",
       " 'geometrica',\n",
       " 'Distribucion',\n",
       " 'Poisson',\n",
       " 'proceso',\n",
       " 'Poisson',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Contenido',\n",
       " 'Algunas',\n",
       " 'distribuciones',\n",
       " 'continuas',\n",
       " 'probabilidad',\n",
       " 'Distribucion',\n",
       " 'uniforme',\n",
       " 'continua',\n",
       " 'Distribucion',\n",
       " 'normal',\n",
       " 'Areas',\n",
       " 'bajo',\n",
       " 'curva',\n",
       " 'normal',\n",
       " 'Aplicaciones',\n",
       " 'distribucion',\n",
       " 'normal',\n",
       " 'Ejercicios',\n",
       " 'Aproximacion',\n",
       " 'normal',\n",
       " 'binomial',\n",
       " 'Ejercicios',\n",
       " 'Distribucion',\n",
       " 'gamma',\n",
       " 'distribucion',\n",
       " 'exponencial',\n",
       " 'Distribucion',\n",
       " 'cuadrada',\n",
       " 'Distribucion',\n",
       " 'beta',\n",
       " 'Distribucion',\n",
       " 'logaritmica',\n",
       " 'normal',\n",
       " 'Distribucion',\n",
       " 'Weibull',\n",
       " 'opcional',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Funciones',\n",
       " 'variables',\n",
       " 'aleatorias',\n",
       " 'opcional',\n",
       " 'Introduccion',\n",
       " 'variables',\n",
       " 'Momentos',\n",
       " 'funciones',\n",
       " 'generadoras',\n",
       " 'momentos',\n",
       " 'Ejercicios',\n",
       " 'Distribuciones',\n",
       " 'muestreo',\n",
       " 'fundamentales',\n",
       " 'descripciones',\n",
       " 'datos',\n",
       " 'Muestreo',\n",
       " 'aleatorio',\n",
       " 'Algunos',\n",
       " 'estadisticos',\n",
       " 'importantes',\n",
       " 'Ejercicios',\n",
       " 'Distribuciones',\n",
       " 'muestrales',\n",
       " 'Distribucion',\n",
       " 'muestral',\n",
       " 'medias',\n",
       " 'teorema',\n",
       " 'limite',\n",
       " 'central',\n",
       " 'Ejercicios',\n",
       " 'Distribucion',\n",
       " 'muestral',\n",
       " 'Distribucion',\n",
       " 'Distribucion',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Contenido8',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Problemas',\n",
       " 'estimacion',\n",
       " 'muestras',\n",
       " 'Introduccion',\n",
       " 'Inferencia',\n",
       " 'estadistica',\n",
       " 'Metodos',\n",
       " 'estimacion',\n",
       " 'clasicos',\n",
       " 'sola',\n",
       " 'muestra',\n",
       " 'estimacion',\n",
       " 'media',\n",
       " 'Error',\n",
       " 'estandar',\n",
       " 'estimacion',\n",
       " 'puntual',\n",
       " 'Intervalos',\n",
       " 'prediccion',\n",
       " 'Limites',\n",
       " 'tolerancia',\n",
       " 'Ejercicios',\n",
       " 'muestras',\n",
       " 'estimacion',\n",
       " 'diferencia',\n",
       " 'entre',\n",
       " 'medias',\n",
       " 'Observaciones',\n",
       " 'pareadas',\n",
       " 'Ejercicios',\n",
       " 'sola',\n",
       " 'muestra',\n",
       " 'estimacion',\n",
       " 'proporcion',\n",
       " 'muestras',\n",
       " 'estimacion',\n",
       " 'diferencia',\n",
       " 'entre',\n",
       " 'proporciones',\n",
       " 'Ejercicios',\n",
       " 'sola',\n",
       " 'muestra',\n",
       " 'estimacion',\n",
       " 'varianza',\n",
       " 'muestras',\n",
       " 'estimacion',\n",
       " 'proporcion',\n",
       " 'varianzas',\n",
       " 'Ejercicios',\n",
       " 'Estimacion',\n",
       " 'maxima',\n",
       " 'verosimilitud',\n",
       " 'opcional',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Pruebas',\n",
       " 'hipotesis',\n",
       " 'muestras',\n",
       " 'Hipotesis',\n",
       " 'estadisticas',\n",
       " 'conceptos',\n",
       " 'generales',\n",
       " 'Prueba',\n",
       " 'hipotesis',\n",
       " 'estadistica',\n",
       " 'valores',\n",
       " 'para',\n",
       " 'toma',\n",
       " 'decisiones',\n",
       " 'prueba',\n",
       " 'hipotesis',\n",
       " 'Ejercicios',\n",
       " 'sola',\n",
       " 'muestra',\n",
       " 'pruebas',\n",
       " 'respecto',\n",
       " 'sola',\n",
       " 'media',\n",
       " 'muestras',\n",
       " 'pruebas',\n",
       " 'sobre',\n",
       " 'medias',\n",
       " 'Eleccion',\n",
       " 'tamano',\n",
       " 'muestra',\n",
       " 'para',\n",
       " 'prueba',\n",
       " 'medias',\n",
       " 'Ejercicios',\n",
       " 'muestra',\n",
       " 'prueba',\n",
       " 'sobre',\n",
       " 'sola',\n",
       " 'proporcion',\n",
       " 'muestras',\n",
       " 'pruebas',\n",
       " 'sobre',\n",
       " 'proporciones',\n",
       " 'Ejercicios',\n",
       " 'Pruebas',\n",
       " 'muestras',\n",
       " 'referentes',\n",
       " 'varianzas',\n",
       " 'Ejercicios',\n",
       " 'Contenido',\n",
       " 'xi10',\n",
       " 'Prueba',\n",
       " 'bondad',\n",
       " 'ajuste',\n",
       " 'Prueba',\n",
       " 'independencia',\n",
       " 'datos',\n",
       " 'categoricos',\n",
       " 'Prueba',\n",
       " 'homogeneidad',\n",
       " 'Estudio',\n",
       " 'caso',\n",
       " 'muestras',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Regresion',\n",
       " 'lineal',\n",
       " 'simple',\n",
       " 'correlacion',\n",
       " 'Introduccion',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'modelo',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'simple',\n",
       " 'Minimos',\n",
       " 'cuadrados',\n",
       " 'modelo',\n",
       " 'ajustado',\n",
       " 'Ejercicios',\n",
       " 'Propiedades',\n",
       " 'estimadores',\n",
       " 'minimos',\n",
       " 'cuadrados',\n",
       " 'gresion',\n",
       " 'Prediccion',\n",
       " 'Ejercicios',\n",
       " 'Seleccion',\n",
       " 'modelo',\n",
       " 'regresion',\n",
       " 'metodo',\n",
       " 'analisis',\n",
       " 'varianza',\n",
       " 'Prueba',\n",
       " 'para',\n",
       " 'linealidad',\n",
       " 'regresion',\n",
       " 'datos',\n",
       " 'observaciones',\n",
       " 'repetidas',\n",
       " 'Ejercicios',\n",
       " 'Estudio',\n",
       " 'caso',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'simple',\n",
       " 'Correlacion',\n",
       " 'Ejercicios',\n",
       " 'Ejercicios',\n",
       " 'repaso',\n",
       " 'Posibles',\n",
       " 'riesgos',\n",
       " 'errores',\n",
       " 'conceptuales',\n",
       " 'relacion',\n",
       " 'material',\n",
       " 'otros',\n",
       " 'capitulos',\n",
       " 'Regresion',\n",
       " 'lineal',\n",
       " 'multiple',\n",
       " 'ciertos',\n",
       " 'modelos',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'Introduccion',\n",
       " 'Modelo',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'utilizan',\n",
       " 'matrices',\n",
       " 'Ejercicios',\n",
       " 'Propiedades',\n",
       " 'estimadores',\n",
       " 'minimos',\n",
       " 'cuadrados',\n",
       " 'Inferencias',\n",
       " 'regresion',\n",
       " 'lineal',\n",
       " 'multiple',\n",
       " 'Ejercicios']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = text_dc.split()\n",
    "tt[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28443"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(set(tt)),columns=['keywords'])  #Dataframe with unique keywords to avoid repetition in rows\n",
    "df[\"lenght\"] = df[\"keywords\"].apply(lambda x: len(str(x)))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15148</td>\n",
       "      <td>acontecimientos</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22614</td>\n",
       "      <td>norteamericanos</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22716</td>\n",
       "      <td>simultaneamente</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18192</td>\n",
       "      <td>probabilisticos</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5644</td>\n",
       "      <td>Operador1234175</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23926</td>\n",
       "      <td>enigmaticamente</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8675</td>\n",
       "      <td>meticulosamente</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24208</td>\n",
       "      <td>revolucionarias</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23957</td>\n",
       "      <td>s23s2ErrorSCEab</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8270</td>\n",
       "      <td>anticonceptivas</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              keywords  lenght\n",
       "15148  acontecimientos      15\n",
       "22614  norteamericanos      15\n",
       "22716  simultaneamente      15\n",
       "18192  probabilisticos      15\n",
       "5644   Operador1234175      15\n",
       "...                ...     ...\n",
       "23926  enigmaticamente      15\n",
       "8675   meticulosamente      15\n",
       "24208  revolucionarias      15\n",
       "23957  s23s2ErrorSCEab      15\n",
       "8270   anticonceptivas      15\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[\"lenght\"], ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightage(word,text,number_of_documents=1):\n",
    "    word_list = re.findall(word,text)\n",
    "    number_of_times_word_appeared =len(word_list)\n",
    "    tf = number_of_times_word_appeared/float(len(text))\n",
    "    idf = np.log((number_of_documents)/float(number_of_times_word_appeared))\n",
    "    tf_idf = tf*idf\n",
    "    return number_of_times_word_appeared,tf,idf ,tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_times_word_appeared'] = df['keywords'].apply(lambda x: weightage(x,text_dc)[0])\n",
    "df['tf'] = df['keywords'].apply(lambda x: weightage(x,text_dc)[1])\n",
    "df['idf'] = df['keywords'].apply(lambda x: weightage(x,text_dc)[2])\n",
    "df['tf_idf'] = df['keywords'].apply(lambda x: weightage(x,text_dc)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>lenght</th>\n",
       "      <th>number_of_times_word_appeared</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11380</td>\n",
       "      <td>cion</td>\n",
       "      <td>4</td>\n",
       "      <td>11124</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>-9.316860</td>\n",
       "      <td>-0.057904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22417</td>\n",
       "      <td>para</td>\n",
       "      <td>4</td>\n",
       "      <td>5220</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-8.560253</td>\n",
       "      <td>-0.024965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3245</td>\n",
       "      <td>acion</td>\n",
       "      <td>5</td>\n",
       "      <td>4897</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>-8.496378</td>\n",
       "      <td>-0.023246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15288</td>\n",
       "      <td>esta</td>\n",
       "      <td>4</td>\n",
       "      <td>3631</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>-8.197263</td>\n",
       "      <td>-0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>aria</td>\n",
       "      <td>4</td>\n",
       "      <td>2932</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-7.983440</td>\n",
       "      <td>-0.013078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2171</td>\n",
       "      <td>medi</td>\n",
       "      <td>4</td>\n",
       "      <td>2543</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>-7.841100</td>\n",
       "      <td>-0.011140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13428</td>\n",
       "      <td>estr</td>\n",
       "      <td>4</td>\n",
       "      <td>2509</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>-7.827640</td>\n",
       "      <td>-0.010973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9489</td>\n",
       "      <td>lidad</td>\n",
       "      <td>5</td>\n",
       "      <td>2432</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>-7.796469</td>\n",
       "      <td>-0.010594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15896</td>\n",
       "      <td>varia</td>\n",
       "      <td>5</td>\n",
       "      <td>2424</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>-7.793174</td>\n",
       "      <td>-0.010554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2835</td>\n",
       "      <td>iones</td>\n",
       "      <td>5</td>\n",
       "      <td>2387</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>-7.777793</td>\n",
       "      <td>-0.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7946</td>\n",
       "      <td>ante</td>\n",
       "      <td>4</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>-7.773594</td>\n",
       "      <td>-0.010324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7497</td>\n",
       "      <td>cont</td>\n",
       "      <td>4</td>\n",
       "      <td>2241</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-7.714677</td>\n",
       "      <td>-0.009659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21701</td>\n",
       "      <td>cione</td>\n",
       "      <td>5</td>\n",
       "      <td>2207</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>-7.699389</td>\n",
       "      <td>-0.009494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10673</td>\n",
       "      <td>ciones</td>\n",
       "      <td>6</td>\n",
       "      <td>2131</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>-7.664347</td>\n",
       "      <td>-0.009125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10733</td>\n",
       "      <td>mues</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>-7.605890</td>\n",
       "      <td>-0.008541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27893</td>\n",
       "      <td>ucion</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>-7.604396</td>\n",
       "      <td>-0.008527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>ados</td>\n",
       "      <td>4</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>-7.584265</td>\n",
       "      <td>-0.008335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25513</td>\n",
       "      <td>encia</td>\n",
       "      <td>5</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>-7.570959</td>\n",
       "      <td>-0.008210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14811</td>\n",
       "      <td>trib</td>\n",
       "      <td>4</td>\n",
       "      <td>1875</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>-7.536364</td>\n",
       "      <td>-0.007895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8252</td>\n",
       "      <td>able</td>\n",
       "      <td>4</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-7.526179</td>\n",
       "      <td>-0.007804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2589</td>\n",
       "      <td>proba</td>\n",
       "      <td>5</td>\n",
       "      <td>1829</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>-7.511525</td>\n",
       "      <td>-0.007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23826</td>\n",
       "      <td>tribu</td>\n",
       "      <td>5</td>\n",
       "      <td>1824</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-7.508787</td>\n",
       "      <td>-0.007652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17387</td>\n",
       "      <td>bilidad</td>\n",
       "      <td>7</td>\n",
       "      <td>1809</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-7.500529</td>\n",
       "      <td>-0.007581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17199</td>\n",
       "      <td>muestra</td>\n",
       "      <td>7</td>\n",
       "      <td>1757</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>-7.471363</td>\n",
       "      <td>-0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9854</td>\n",
       "      <td>abili</td>\n",
       "      <td>5</td>\n",
       "      <td>1755</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>-7.470224</td>\n",
       "      <td>-0.007325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1007</td>\n",
       "      <td>abilidad</td>\n",
       "      <td>8</td>\n",
       "      <td>1701</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>-7.438972</td>\n",
       "      <td>-0.007070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24564</td>\n",
       "      <td>sion</td>\n",
       "      <td>4</td>\n",
       "      <td>1691</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>-7.433075</td>\n",
       "      <td>-0.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18689</td>\n",
       "      <td>distri</td>\n",
       "      <td>6</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>-7.428927</td>\n",
       "      <td>-0.006990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20118</td>\n",
       "      <td>como</td>\n",
       "      <td>4</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-7.403670</td>\n",
       "      <td>-0.006792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12244</td>\n",
       "      <td>distrib</td>\n",
       "      <td>7</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-7.400010</td>\n",
       "      <td>-0.006764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5418</td>\n",
       "      <td>bucion</td>\n",
       "      <td>6</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-7.394493</td>\n",
       "      <td>-0.006722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26739</td>\n",
       "      <td>anza</td>\n",
       "      <td>4</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>-7.385231</td>\n",
       "      <td>-0.006651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9380</td>\n",
       "      <td>distribu</td>\n",
       "      <td>8</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-7.379008</td>\n",
       "      <td>-0.006605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10326</td>\n",
       "      <td>tribucion</td>\n",
       "      <td>9</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>-7.373374</td>\n",
       "      <td>-0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16385</td>\n",
       "      <td>valo</td>\n",
       "      <td>4</td>\n",
       "      <td>1583</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-7.367077</td>\n",
       "      <td>-0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2338</td>\n",
       "      <td>inte</td>\n",
       "      <td>4</td>\n",
       "      <td>1582</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-7.366445</td>\n",
       "      <td>-0.006511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>probabi</td>\n",
       "      <td>7</td>\n",
       "      <td>1496</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>-7.310550</td>\n",
       "      <td>-0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14160</td>\n",
       "      <td>babilidad</td>\n",
       "      <td>9</td>\n",
       "      <td>1495</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>-7.309881</td>\n",
       "      <td>-0.006106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23842</td>\n",
       "      <td>obabilidad</td>\n",
       "      <td>10</td>\n",
       "      <td>1462</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>-7.287561</td>\n",
       "      <td>-0.005953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17781</td>\n",
       "      <td>robabilidad</td>\n",
       "      <td>11</td>\n",
       "      <td>1461</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-7.286876</td>\n",
       "      <td>-0.005948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>probabili</td>\n",
       "      <td>9</td>\n",
       "      <td>1455</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-7.282761</td>\n",
       "      <td>-0.005920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21129</td>\n",
       "      <td>alor</td>\n",
       "      <td>4</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>-7.276556</td>\n",
       "      <td>-0.005879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25844</td>\n",
       "      <td>mente</td>\n",
       "      <td>5</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-7.275865</td>\n",
       "      <td>-0.005874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4343</td>\n",
       "      <td>distribucio</td>\n",
       "      <td>11</td>\n",
       "      <td>1443</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>-7.274480</td>\n",
       "      <td>-0.005865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26555</td>\n",
       "      <td>distribucion</td>\n",
       "      <td>12</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>-7.271704</td>\n",
       "      <td>-0.005846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5011</td>\n",
       "      <td>probabilida</td>\n",
       "      <td>11</td>\n",
       "      <td>1417</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>-7.256297</td>\n",
       "      <td>-0.005745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12550</td>\n",
       "      <td>probabilidad</td>\n",
       "      <td>12</td>\n",
       "      <td>1416</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-7.255591</td>\n",
       "      <td>-0.005740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12644</td>\n",
       "      <td>rado</td>\n",
       "      <td>4</td>\n",
       "      <td>1407</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-7.249215</td>\n",
       "      <td>-0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>inter</td>\n",
       "      <td>5</td>\n",
       "      <td>1374</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-7.225481</td>\n",
       "      <td>-0.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25310</td>\n",
       "      <td>toria</td>\n",
       "      <td>5</td>\n",
       "      <td>1335</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-7.196687</td>\n",
       "      <td>-0.005368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keywords  lenght  number_of_times_word_appeared        tf  \\\n",
       "11380          cion       4                          11124  0.006215   \n",
       "22417          para       4                           5220  0.002916   \n",
       "3245          acion       5                           4897  0.002736   \n",
       "15288          esta       4                           3631  0.002029   \n",
       "1499           aria       4                           2932  0.001638   \n",
       "2171           medi       4                           2543  0.001421   \n",
       "13428          estr       4                           2509  0.001402   \n",
       "9489          lidad       5                           2432  0.001359   \n",
       "15896         varia       5                           2424  0.001354   \n",
       "2835          iones       5                           2387  0.001334   \n",
       "7946           ante       4                           2377  0.001328   \n",
       "7497           cont       4                           2241  0.001252   \n",
       "21701         cione       5                           2207  0.001233   \n",
       "10673        ciones       6                           2131  0.001191   \n",
       "10733          mues       4                           2010  0.001123   \n",
       "27893         ucion       5                           2007  0.001121   \n",
       "110            ados       4                           1967  0.001099   \n",
       "25513         encia       5                           1941  0.001084   \n",
       "14811          trib       4                           1875  0.001048   \n",
       "8252           able       4                           1856  0.001037   \n",
       "2589          proba       5                           1829  0.001022   \n",
       "23826         tribu       5                           1824  0.001019   \n",
       "17387       bilidad       7                           1809  0.001011   \n",
       "17199       muestra       7                           1757  0.000982   \n",
       "9854          abili       5                           1755  0.000981   \n",
       "1007       abilidad       8                           1701  0.000950   \n",
       "24564          sion       4                           1691  0.000945   \n",
       "18689        distri       6                           1684  0.000941   \n",
       "20118          como       4                           1642  0.000917   \n",
       "12244       distrib       7                           1636  0.000914   \n",
       "5418         bucion       6                           1627  0.000909   \n",
       "26739          anza       4                           1612  0.000901   \n",
       "9380       distribu       8                           1602  0.000895   \n",
       "10326     tribucion       9                           1593  0.000890   \n",
       "16385          valo       4                           1583  0.000884   \n",
       "2338           inte       4                           1582  0.000884   \n",
       "14000       probabi       7                           1496  0.000836   \n",
       "14160     babilidad       9                           1495  0.000835   \n",
       "23842    obabilidad      10                           1462  0.000817   \n",
       "17781   robabilidad      11                           1461  0.000816   \n",
       "453       probabili       9                           1455  0.000813   \n",
       "21129          alor       4                           1446  0.000808   \n",
       "25844         mente       5                           1445  0.000807   \n",
       "4343    distribucio      11                           1443  0.000806   \n",
       "26555  distribucion      12                           1439  0.000804   \n",
       "5011    probabilida      11                           1417  0.000792   \n",
       "12550  probabilidad      12                           1416  0.000791   \n",
       "12644          rado       4                           1407  0.000786   \n",
       "4740          inter       5                           1374  0.000768   \n",
       "25310         toria       5                           1335  0.000746   \n",
       "\n",
       "            idf    tf_idf  \n",
       "11380 -9.316860 -0.057904  \n",
       "22417 -8.560253 -0.024965  \n",
       "3245  -8.496378 -0.023246  \n",
       "15288 -8.197263 -0.016629  \n",
       "1499  -7.983440 -0.013078  \n",
       "2171  -7.841100 -0.011140  \n",
       "13428 -7.827640 -0.010973  \n",
       "9489  -7.796469 -0.010594  \n",
       "15896 -7.793174 -0.010554  \n",
       "2835  -7.777793 -0.010373  \n",
       "7946  -7.773594 -0.010324  \n",
       "7497  -7.714677 -0.009659  \n",
       "21701 -7.699389 -0.009494  \n",
       "10673 -7.664347 -0.009125  \n",
       "10733 -7.605890 -0.008541  \n",
       "27893 -7.604396 -0.008527  \n",
       "110   -7.584265 -0.008335  \n",
       "25513 -7.570959 -0.008210  \n",
       "14811 -7.536364 -0.007895  \n",
       "8252  -7.526179 -0.007804  \n",
       "2589  -7.511525 -0.007676  \n",
       "23826 -7.508787 -0.007652  \n",
       "17387 -7.500529 -0.007581  \n",
       "17199 -7.471363 -0.007334  \n",
       "9854  -7.470224 -0.007325  \n",
       "1007  -7.438972 -0.007070  \n",
       "24564 -7.433075 -0.007023  \n",
       "18689 -7.428927 -0.006990  \n",
       "20118 -7.403670 -0.006792  \n",
       "12244 -7.400010 -0.006764  \n",
       "5418  -7.394493 -0.006722  \n",
       "26739 -7.385231 -0.006651  \n",
       "9380  -7.379008 -0.006605  \n",
       "10326 -7.373374 -0.006562  \n",
       "16385 -7.367077 -0.006516  \n",
       "2338  -7.366445 -0.006511  \n",
       "14000 -7.310550 -0.006110  \n",
       "14160 -7.309881 -0.006106  \n",
       "23842 -7.287561 -0.005953  \n",
       "17781 -7.286876 -0.005948  \n",
       "453   -7.282761 -0.005920  \n",
       "21129 -7.276556 -0.005879  \n",
       "25844 -7.275865 -0.005874  \n",
       "4343  -7.274480 -0.005865  \n",
       "26555 -7.271704 -0.005846  \n",
       "5011  -7.256297 -0.005745  \n",
       "12550 -7.255591 -0.005740  \n",
       "12644 -7.249215 -0.005699  \n",
       "4740  -7.225481 -0.005547  \n",
       "25310 -7.196687 -0.005368  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('tf_idf',ascending=True)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.summarization import keywords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4109"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = keywords(text=text_dc,split=True,scores=True, lemmatize=True)\n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>para</td>\n",
       "      <td>0.428643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>comoe</td>\n",
       "      <td>0.260384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>habia</td>\n",
       "      <td>0.134874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pero</td>\n",
       "      <td>0.129767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>estas</td>\n",
       "      <td>0.112177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>valor</td>\n",
       "      <td>0.106625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>donde</td>\n",
       "      <td>0.105266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>siempre cuando</td>\n",
       "      <td>0.102367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>casas</td>\n",
       "      <td>0.094130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>tiempos</td>\n",
       "      <td>0.092058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>todo</td>\n",
       "      <td>0.091622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>entres</td>\n",
       "      <td>0.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>cual</td>\n",
       "      <td>0.090709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>muestraes</td>\n",
       "      <td>0.089963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ursula</td>\n",
       "      <td>0.089703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>cadas</td>\n",
       "      <td>0.087771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>aurelianos</td>\n",
       "      <td>0.086526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>entonces</td>\n",
       "      <td>0.085437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>tantos</td>\n",
       "      <td>0.083884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>estes</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>sobr</td>\n",
       "      <td>0.080903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>ella</td>\n",
       "      <td>0.077863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>prueba</td>\n",
       "      <td>0.076602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>estabas</td>\n",
       "      <td>0.075785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>modeloe</td>\n",
       "      <td>0.067349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keyword     score\n",
       "0             para  0.428643\n",
       "1            comoe  0.260384\n",
       "2            habia  0.134874\n",
       "3             pero  0.129767\n",
       "4            estas  0.112177\n",
       "5            valor  0.106625\n",
       "6            donde  0.105266\n",
       "7   siempre cuando  0.102367\n",
       "8            casas  0.094130\n",
       "9          tiempos  0.092058\n",
       "10            todo  0.091622\n",
       "11          entres  0.091590\n",
       "12            cual  0.090709\n",
       "13       muestraes  0.089963\n",
       "14          ursula  0.089703\n",
       "15           cadas  0.087771\n",
       "16      aurelianos  0.086526\n",
       "17        entonces  0.085437\n",
       "18          tantos  0.083884\n",
       "19           estes  0.081767\n",
       "20            sobr  0.080903\n",
       "21            ella  0.077863\n",
       "22          prueba  0.076602\n",
       "23         estabas  0.075785\n",
       "24         modeloe  0.067349"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(values,columns=['keyword','score'])\n",
    "data = data.sort_values('score',ascending=False)\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing with NLP!! ðŸ¤¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('spanish')\n",
    "todos_stops = STOPWORDS.union(set(stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2 = df[df['lenght'] >=3]\n",
    "pd2 = pd2[~df['keywords'].isin(todos_stops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>lenght</th>\n",
       "      <th>number_of_times_word_appeared</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1044</td>\n",
       "      <td>ando</td>\n",
       "      <td>4</td>\n",
       "      <td>219</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>-5.389072</td>\n",
       "      <td>-0.013348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2547</td>\n",
       "      <td>mente</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>-4.691348</td>\n",
       "      <td>-0.005783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>tras</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>-4.672829</td>\n",
       "      <td>-0.005655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>senti</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-4.406719</td>\n",
       "      <td>-0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2081</td>\n",
       "      <td>mano</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-4.406719</td>\n",
       "      <td>-0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>habia</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-4.343805</td>\n",
       "      <td>-0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2069</td>\n",
       "      <td>bien</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>-4.234107</td>\n",
       "      <td>-0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3374</td>\n",
       "      <td>hacia</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>-4.174387</td>\n",
       "      <td>-0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3482</td>\n",
       "      <td>hace</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>-4.174387</td>\n",
       "      <td>-0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3106</td>\n",
       "      <td>anos</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>-4.110874</td>\n",
       "      <td>-0.002836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>boca</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>-4.094345</td>\n",
       "      <td>-0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2413</td>\n",
       "      <td>mira</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-4.077537</td>\n",
       "      <td>-0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4605</td>\n",
       "      <td>bamos</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-4.043051</td>\n",
       "      <td>-0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3744</td>\n",
       "      <td>pare</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>-4.007333</td>\n",
       "      <td>-0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>tenia</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>-3.951244</td>\n",
       "      <td>-0.002324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2799</td>\n",
       "      <td>cada</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-3.931826</td>\n",
       "      <td>-0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>deja</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-3.891820</td>\n",
       "      <td>-0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4662</td>\n",
       "      <td>beso</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-3.891820</td>\n",
       "      <td>-0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3704</td>\n",
       "      <td>pasa</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>-3.871201</td>\n",
       "      <td>-0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2922</td>\n",
       "      <td>Pero</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>-3.850148</td>\n",
       "      <td>-0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2096</td>\n",
       "      <td>noche</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>-3.850148</td>\n",
       "      <td>-0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4442</td>\n",
       "      <td>entro</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>-3.806662</td>\n",
       "      <td>-0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>ojos</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>-3.806662</td>\n",
       "      <td>-0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2707</td>\n",
       "      <td>hacer</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>-3.737670</td>\n",
       "      <td>-0.001775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>cabe</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-3.713572</td>\n",
       "      <td>-0.001722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keywords  lenght  number_of_times_word_appeared        tf       idf  \\\n",
       "1044     ando       4                            219  0.002477 -5.389072   \n",
       "2547    mente       5                            109  0.001233 -4.691348   \n",
       "1370     tras       4                            107  0.001210 -4.672829   \n",
       "1116    senti       5                             82  0.000927 -4.406719   \n",
       "2081     mano       4                             82  0.000927 -4.406719   \n",
       "1525    habia       5                             77  0.000871 -4.343805   \n",
       "2069     bien       4                             69  0.000780 -4.234107   \n",
       "3374    hacia       5                             65  0.000735 -4.174387   \n",
       "3482     hace       4                             65  0.000735 -4.174387   \n",
       "3106     anos       4                             61  0.000690 -4.110874   \n",
       "4625     boca       4                             60  0.000679 -4.094345   \n",
       "2413     mira       4                             59  0.000667 -4.077537   \n",
       "4605    bamos       5                             57  0.000645 -4.043051   \n",
       "3744     pare       4                             55  0.000622 -4.007333   \n",
       "1098    tenia       5                             52  0.000588 -3.951244   \n",
       "2799     cada       4                             51  0.000577 -3.931826   \n",
       "1498     deja       4                             49  0.000554 -3.891820   \n",
       "4662     beso       4                             49  0.000554 -3.891820   \n",
       "3704     pasa       4                             48  0.000543 -3.871201   \n",
       "2922     Pero       4                             47  0.000532 -3.850148   \n",
       "2096    noche       5                             47  0.000532 -3.850148   \n",
       "4442    entro       5                             45  0.000509 -3.806662   \n",
       "260      ojos       4                             45  0.000509 -3.806662   \n",
       "2707    hacer       5                             42  0.000475 -3.737670   \n",
       "1599     cabe       4                             41  0.000464 -3.713572   \n",
       "\n",
       "        tf_idf  \n",
       "1044 -0.013348  \n",
       "2547 -0.005783  \n",
       "1370 -0.005655  \n",
       "1116 -0.004087  \n",
       "2081 -0.004087  \n",
       "1525 -0.003783  \n",
       "2069 -0.003304  \n",
       "3374 -0.003069  \n",
       "3482 -0.003069  \n",
       "3106 -0.002836  \n",
       "4625 -0.002778  \n",
       "2413 -0.002721  \n",
       "4605 -0.002606  \n",
       "3744 -0.002493  \n",
       "1098 -0.002324  \n",
       "2799 -0.002268  \n",
       "1498 -0.002157  \n",
       "4662 -0.002157  \n",
       "3704 -0.002102  \n",
       "2922 -0.002047  \n",
       "2096 -0.002047  \n",
       "4442 -0.001937  \n",
       "260  -0.001937  \n",
       "2707 -0.001775  \n",
       "1599 -0.001722  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd2 = pd2.sort_values('tf_idf',ascending=True)\n",
    "pd2.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM with NLP!! ðŸ¤¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dc_nlp = \" \".join([stemmer.stem(word) for word in text_dc.split() if word not in todos_stops])\n",
    "values_nlp = keywords(text=text_dc_nlp,split=True,scores=True, lemmatize=True)\n",
    "len(values_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>desliz</td>\n",
       "      <td>0.013288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.013288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>mujer</td>\n",
       "      <td>0.013339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>segua</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>tradicion</td>\n",
       "      <td>0.013367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>edad</td>\n",
       "      <td>0.013426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>dich</td>\n",
       "      <td>0.013430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>oficin</td>\n",
       "      <td>0.013477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>desafi</td>\n",
       "      <td>0.013490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>habitacion</td>\n",
       "      <td>0.013499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>aunqu</td>\n",
       "      <td>0.013544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>usted</td>\n",
       "      <td>0.013565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>adem</td>\n",
       "      <td>0.013584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>tet</td>\n",
       "      <td>0.013590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>tem</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>clas</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>entend</td>\n",
       "      <td>0.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>vuelv</td>\n",
       "      <td>0.013639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>vient</td>\n",
       "      <td>0.013646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>sigui</td>\n",
       "      <td>0.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>intencion</td>\n",
       "      <td>0.013763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>misteri</td>\n",
       "      <td>0.013852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>curs</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>cel</td>\n",
       "      <td>0.013892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>estacion</td>\n",
       "      <td>0.013915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword     score\n",
       "426      desliz  0.013288\n",
       "425     correct  0.013288\n",
       "424       mujer  0.013339\n",
       "423       segua  0.013340\n",
       "422   tradicion  0.013367\n",
       "421        edad  0.013426\n",
       "420        dich  0.013430\n",
       "419      oficin  0.013477\n",
       "418      desafi  0.013490\n",
       "417  habitacion  0.013499\n",
       "416       aunqu  0.013544\n",
       "415       usted  0.013565\n",
       "414        adem  0.013584\n",
       "413         tet  0.013590\n",
       "412         tem  0.013592\n",
       "411        clas  0.013600\n",
       "410      entend  0.013611\n",
       "409       vuelv  0.013639\n",
       "408       vient  0.013646\n",
       "407       sigui  0.013664\n",
       "406   intencion  0.013763\n",
       "405     misteri  0.013852\n",
       "404        curs  0.013877\n",
       "403         cel  0.013892\n",
       "402    estacion  0.013915"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nlp = pd.DataFrame(values_nlp,columns=['keyword','score'])\n",
    "data_nlp = data_nlp.sort_values('score',ascending=True)\n",
    "data_nlp.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"keyword\"].to_json(\"taxonomy_export_2.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "r.extract_keywords_from_text(text_dc_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.558757e+06</td>\n",
       "      <td>mir sonrisit haci import anim escrib grup facebook facult supuest consult trabaj hol prof com hol quer lor bien mir entiend punt trabaj mand trat usted tant anos diferent estuv habl buen rat confianz habi mayor tiemp amist podri dec porqu ten novi pregunt porqu nadi mir dij culmin jaj entiend hermos esas simpl palabr bast derrit dud estari cas dij nunc habi situacion hombr cas per realment import cas profesor martinez entre cos qued junt entre mir mir hotel cerc centr entram pareci joven nunc habi verguenz permiti mir ojos com podi unic pens devorarmel igual per coraj acerc bes suavement senti nin jam habi bes nadi comenc sent clim cad carici pas lengu cad part maner eriz sac cordur sol queri agarr darl teni energ brutal queri termin queri dier calor cad movimient form agarr haci lleg glori com explicart form entreg perr salvaj queri solt pele esas hor intermin poc sal sol podi qued marc memori finaliz bes sal suced proxim encuentr miercol biologi nuestr mir delat pec per unic debi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.244545e+06</td>\n",
       "      <td>part cuerp senti gust encant sent per aguant queri ten adentr pedi hic empez tres cuatr cinc seis siet segui segui rap lent fuert plac sent bien adentr mir ric ric cogi tant podi des dejab hac espald poni cuatr segui metiendomel tod senti volv loc calor calor senti calor queri par per queri ten boc queri chup tod hic sent meti tod boc adentr podi pas lengu encant pas lengu abaj punt sent gargant sub baj apret labi sent sabor gust vuelv loc pidi sub sent encim abri piern cad lad dej entrar senti cuerp abri dej pas bien adentr comenc mov cintur gust mientr chup tet jug pezon apret agarr dient hac gem demasi plac dab empec sent sensacion desd boc baj cuerp cosquille haci tembl piern queri adentr fuert rap plac demasi ric demasi perfect haci bien teni teni sol ador hic cuerp quis quis acab cam jug mejor sali gust hac amor pasion identific amig derech conoci hac anos fuim companer secundari music tribut rock nacional com despist eram tant edad pav jam enter habi hac reserv encontrab par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.797720e+06</td>\n",
       "      <td>frent particul imag borros dab entend hombr braz larg enroll cintur figur human muj tom cader seduj bes cerr ojos dej sent suavid boc alient ment labi carnos tant tentacion consum aquel fogos bes prendi tel conect driv vam segu music aut dej des dij mientr busc playlist baj nombr especial ris tim teni prepar situacion agus conect siempr tom man dirigi habitacion esto bomb tiemp nen mism desintegr escenografi esper chisp incendi empiez incendi empiez abraz pintur braz enroll cintur apoy puert placard bes much tiemp senti boc suav baj cuell halag perfum man sub enred cabez apoy palm car entre ded qued orej eran bes simpl bes calient necesitab chisp deton opte gir dej merc palm desliz car pech jug rop baj entrepiern roz unas aquel pantalon mayordom har senor bien pued violador imaginacion noch pued estoy mur propi piel hac sent infiern llevar extrem situacion pus salvaj tom rul arroj cam pareci hab deton chisp prend incendi subi encim fier atac pres dient adher cuell transgresion proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.671927e+06</td>\n",
       "      <td>deci cad sali algun conversacion tip cervez amig ciert siempr vei feliz confes jam habi cont azul senti vaci escribi javi dic dej pens extran quier volv amig quier mism mied pued mied feliz bien gan cos salg todavi acuerd pas leandr sufri javi excelent mir enseri otra oportun apart facu pued distr flor mam quier cerc tiemp cos estan toc porter llam vuelt eran cinc tard habi quit pijam almuerz mat teni apetit cenicer llen colill blanc hol javi hac nad buen subi arregl rap pel limpi maquillaj corr anterior acomod sillon arrib javi mir dulzur tristez sabi bien tom braz fuert apret junt pech azul pud evit ojos cristaliz dese ten tod vid permiti feliz amab nunc habi tant vec repiti valor ahor senti realment dab mied quier pronunci temi sent vulner fragil perd control pensamient sentimient quer hac locur dars complet pens podi volv pedaz ultim javi habi convert algui import podi dej situacion man gan vers traduci bes mir mir confes carici suen rot volvi armars cad tom man sabi roz hombr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.581444e+06</td>\n",
       "      <td>siempr desliz mir crei mir pill vec entonc sol sonrei pas principi molest travesur hombr hac gent dich buen espect teni ningun anill ded pens probabl tendri novi amant novi nunc sab dias per ultim haci lanz mir realment comi ojos trav espej ascensor segui siempr sonris pill embarg dab prim pas pes muchisim des durant siguient dias comport hiz pens realment interes sol pareci gracios ide fastidi infiern encontr ascensor noch frunci cen hiz rutin com ojos sonris desapareci frunc cen verd pareci gracios mir desvi pantalon dond habil distingu ereccion pens chist tendri ereccion verd sabi cad fibr teni grand ahor mism ascensor vaci adem setent pis lleg vestibul teni tant curi decidi lleg fond misteri pas cerc tante musl estab efect total despiert palideci ojos vol salvaj contempl expresion incredul punt bastant segur gritari tard presentari carg acos sexual llegas plant baj sorprendi hiz muec dij rein consegu primer habl profund ronc firm masculin sexy antes pud dec palabr barri suel em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.205799e+06</td>\n",
       "      <td>frent acompan paisaj calor boc calient disfrut mod avanz usted tambi disfrut dej toc cuand entreg col gui man pong ded boc moj sent arrib busc punt plac secret pequen golpecit yem ded met despaci despaci tecnic casi levant ded sol dej apoy col com sol par plac erot nombr haci pus cuatr arrib dandol espald pas tod conch moj pech omblig llev cuerp boc bes cul nunc nadi habi hech nunc dej algui hic teni cerc masaj chin habi mim rat simul man bol grand cuatr palit cad palit termin bolit unto col aceit masaj despacit empez met bolit chiquit col comi tod piel ajust improvis juguet algo sol haci dad bien llevab cam dej llen car boc abiert acab mori senti tibi sali cuerp habi caus premi regal par existi plac erot romant basic enamor pas plac normal unic ella chic siet anos vol cabez moment espontan teni queri hac lad manej plen call martin empez desprend pantalon sac pij empez chup noo paraa encant haci lad queri pequ ninfoman nunc pens pendej anos bolud grandot dier conoc tant sensacion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.828327e+05</td>\n",
       "      <td>abrupt crecimient entrepiern llam toc antes inclus dud tom man pus direct tronc tel jeans ante endebl caract situacion min dud desabroch boton separ lujuri plac tangibl corri rop tom tronc fierez determinacion sac pech rap movimient mientr palabr concis brot instint hermos pij ten titub baj rodill suel adopt posicion sumis mir haci arrib pid permis empun haci boc blanque ojos dej hac sabi pas lengu contorn larg miembr lubric saliv mientr humed tom juguet pezon ros pellizc masaj acompan movimient tiemp levant braz fuerz gir ella apoy palm abiert par acarici mientr encorv espald facund man derech desprend boton pantalon min termin baj plieg sep col piern mientr antebraz izquierd haci presion espald alta asegur mov intent alej hic agarr tronc busc glute perfect redond puert entrad extasis gem mezcl dolor sorpres sali boc sosteni cintur hiz carg cad movimient podi leer cuerp pedi grit sabi hac lleg punt mujer vuelv loc mordi cuell deton moment final contraccion cuerp min incendi facu e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.748261e+05</td>\n",
       "      <td>moment mariel alej sient oid etern esper instant cierr ojos sient man met disimul abaj fald abro encuentr esper secret hac present trat evident mir irresist camis negr plen pantalon jean ajust barb recort perfeccion pel rubi oscur cort acomod dese hac present conoc fiest quier piens acerc mariel present amig hac mir leon pres expect moment alej pront vendr nuev llen gent alej mes empiez bail bail junt temperatur empiez aument bes vien bes veng dig ban camin ban man agarr llev ban discapacit grand cierr puert pon trab hund cuell sab calient sab ambos jadeant dese animal salvaj actu sol instint baj fald desprend pantalon denot ereccion crecient baj box hund ansi boc sex prueb disfrut despu instant levant pon man par sient plac hund cuerp incont vec gem extasis inconmesur ven des hac met man escot dars impuls plac constant cuant tiemp pas frenesi acab fund bes apasion import acomod rop pel haci mism destrab puert ban encontr mariel cre sospech alcohol encim dij event termin genial ami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.612166e+05</td>\n",
       "      <td>televisor sabi hac cam dij mir hac cam probabl termin durm dij sonr desafi hic sof qued cam plaz recost lad gan pon pelicul cre ment pas mism bes boc pas segu obvi pareci habi empez cam casi bes aument mord suav labi rop cayend cost sof dandom cuent rot noch tambi necesit calor cuand desnud qued subi arrib plac sex suav lent mientr cabalg man recorr piel pech mientr corri pel larg tap car cuant tiemp pas extasis agot lad mir sup inmediat segu baj lent sex zambull profund dandom plac lengu ded gemi plac haci tiemp senti clav unas hombr extasi plac pront senti aquell fueg artificial caracteriz orgasm cuent levant suavement volvi bes intens boc habl palabr tampoc hiz falt ahor domin situacion subi nuev arrib llev miembr boc sabor mientr vei cerr ojos extasi volvi cabalg senti lleg orgasm recost mir ojos reim reim bes nuev reim qued post extasis cuant tiemp tampoc import despu empez busc rop vest prendi cigarrill cuand termin bes boc susurr cab cuatr manan abri puert volv bes irse sup ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.555283e+05</td>\n",
       "      <td>look llam atencion cun salon viend tel pus junt agach cog objet habi suel podri dec pus nalg delant car cuand levant mir dirigi sonris maner darl verd jug conmig bien accion pareci habi paraliz fond sabi habi encant repent mir direct ojos autent lob cel dij dic gust balbuc dij muj precios novi herman bastant dij buen vam famili seri ideal conocier cre dirigi mir direct paquet pon bien dur soldadit bastant inquiet dej mir cun qued inmoviliz acerqu desabroch pantalon qued sol slips paquet descomunal empec toc guarr encant hac dij cun cun med masturb empez bes cuell mientr cogi fuertement pech segui masturb moment dad pus ofreci con bien humed saci buen perrit lamedor empez chup form increibl bien haci puneter queri par volv total loc segu lleg orgasm habi premi esmer chic dispus com miembr fond arrib abaj dentr corri ensegu menud tronc ties teni comi jug saladit extraordinari cun total entreg pies bastant excit pus cuatr pat darm unas buen acomet cos descomunal hac guarr nunc pen ent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score  \\\n",
       "0  3.558757e+06   \n",
       "1  3.244545e+06   \n",
       "2  1.797720e+06   \n",
       "3  1.671927e+06   \n",
       "4  1.581444e+06   \n",
       "5  1.205799e+06   \n",
       "6  3.828327e+05   \n",
       "7  3.748261e+05   \n",
       "8  3.612166e+05   \n",
       "9  3.555283e+05   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Phrase  \n",
       "0  mir sonrisit haci import anim escrib grup facebook facult supuest consult trabaj hol prof com hol quer lor bien mir entiend punt trabaj mand trat usted tant anos diferent estuv habl buen rat confianz habi mayor tiemp amist podri dec porqu ten novi pregunt porqu nadi mir dij culmin jaj entiend hermos esas simpl palabr bast derrit dud estari cas dij nunc habi situacion hombr cas per realment import cas profesor martinez entre cos qued junt entre mir mir hotel cerc centr entram pareci joven nunc habi verguenz permiti mir ojos com podi unic pens devorarmel igual per coraj acerc bes suavement senti nin jam habi bes nadi comenc sent clim cad carici pas lengu cad part maner eriz sac cordur sol queri agarr darl teni energ brutal queri termin queri dier calor cad movimient form agarr haci lleg glori com explicart form entreg perr salvaj queri solt pele esas hor intermin poc sal sol podi qued marc memori finaliz bes sal suced proxim encuentr miercol biologi nuestr mir delat pec per unic debi...  \n",
       "1  part cuerp senti gust encant sent per aguant queri ten adentr pedi hic empez tres cuatr cinc seis siet segui segui rap lent fuert plac sent bien adentr mir ric ric cogi tant podi des dejab hac espald poni cuatr segui metiendomel tod senti volv loc calor calor senti calor queri par per queri ten boc queri chup tod hic sent meti tod boc adentr podi pas lengu encant pas lengu abaj punt sent gargant sub baj apret labi sent sabor gust vuelv loc pidi sub sent encim abri piern cad lad dej entrar senti cuerp abri dej pas bien adentr comenc mov cintur gust mientr chup tet jug pezon apret agarr dient hac gem demasi plac dab empec sent sensacion desd boc baj cuerp cosquille haci tembl piern queri adentr fuert rap plac demasi ric demasi perfect haci bien teni teni sol ador hic cuerp quis quis acab cam jug mejor sali gust hac amor pasion identific amig derech conoci hac anos fuim companer secundari music tribut rock nacional com despist eram tant edad pav jam enter habi hac reserv encontrab par...  \n",
       "2  frent particul imag borros dab entend hombr braz larg enroll cintur figur human muj tom cader seduj bes cerr ojos dej sent suavid boc alient ment labi carnos tant tentacion consum aquel fogos bes prendi tel conect driv vam segu music aut dej des dij mientr busc playlist baj nombr especial ris tim teni prepar situacion agus conect siempr tom man dirigi habitacion esto bomb tiemp nen mism desintegr escenografi esper chisp incendi empiez incendi empiez abraz pintur braz enroll cintur apoy puert placard bes much tiemp senti boc suav baj cuell halag perfum man sub enred cabez apoy palm car entre ded qued orej eran bes simpl bes calient necesitab chisp deton opte gir dej merc palm desliz car pech jug rop baj entrepiern roz unas aquel pantalon mayordom har senor bien pued violador imaginacion noch pued estoy mur propi piel hac sent infiern llevar extrem situacion pus salvaj tom rul arroj cam pareci hab deton chisp prend incendi subi encim fier atac pres dient adher cuell transgresion proc...  \n",
       "3  deci cad sali algun conversacion tip cervez amig ciert siempr vei feliz confes jam habi cont azul senti vaci escribi javi dic dej pens extran quier volv amig quier mism mied pued mied feliz bien gan cos salg todavi acuerd pas leandr sufri javi excelent mir enseri otra oportun apart facu pued distr flor mam quier cerc tiemp cos estan toc porter llam vuelt eran cinc tard habi quit pijam almuerz mat teni apetit cenicer llen colill blanc hol javi hac nad buen subi arregl rap pel limpi maquillaj corr anterior acomod sillon arrib javi mir dulzur tristez sabi bien tom braz fuert apret junt pech azul pud evit ojos cristaliz dese ten tod vid permiti feliz amab nunc habi tant vec repiti valor ahor senti realment dab mied quier pronunci temi sent vulner fragil perd control pensamient sentimient quer hac locur dars complet pens podi volv pedaz ultim javi habi convert algui import podi dej situacion man gan vers traduci bes mir mir confes carici suen rot volvi armars cad tom man sabi roz hombr ...  \n",
       "4  siempr desliz mir crei mir pill vec entonc sol sonrei pas principi molest travesur hombr hac gent dich buen espect teni ningun anill ded pens probabl tendri novi amant novi nunc sab dias per ultim haci lanz mir realment comi ojos trav espej ascensor segui siempr sonris pill embarg dab prim pas pes muchisim des durant siguient dias comport hiz pens realment interes sol pareci gracios ide fastidi infiern encontr ascensor noch frunci cen hiz rutin com ojos sonris desapareci frunc cen verd pareci gracios mir desvi pantalon dond habil distingu ereccion pens chist tendri ereccion verd sabi cad fibr teni grand ahor mism ascensor vaci adem setent pis lleg vestibul teni tant curi decidi lleg fond misteri pas cerc tante musl estab efect total despiert palideci ojos vol salvaj contempl expresion incredul punt bastant segur gritari tard presentari carg acos sexual llegas plant baj sorprendi hiz muec dij rein consegu primer habl profund ronc firm masculin sexy antes pud dec palabr barri suel em...  \n",
       "5  frent acompan paisaj calor boc calient disfrut mod avanz usted tambi disfrut dej toc cuand entreg col gui man pong ded boc moj sent arrib busc punt plac secret pequen golpecit yem ded met despaci despaci tecnic casi levant ded sol dej apoy col com sol par plac erot nombr haci pus cuatr arrib dandol espald pas tod conch moj pech omblig llev cuerp boc bes cul nunc nadi habi hech nunc dej algui hic teni cerc masaj chin habi mim rat simul man bol grand cuatr palit cad palit termin bolit unto col aceit masaj despacit empez met bolit chiquit col comi tod piel ajust improvis juguet algo sol haci dad bien llevab cam dej llen car boc abiert acab mori senti tibi sali cuerp habi caus premi regal par existi plac erot romant basic enamor pas plac normal unic ella chic siet anos vol cabez moment espontan teni queri hac lad manej plen call martin empez desprend pantalon sac pij empez chup noo paraa encant haci lad queri pequ ninfoman nunc pens pendej anos bolud grandot dier conoc tant sensacion n...  \n",
       "6  abrupt crecimient entrepiern llam toc antes inclus dud tom man pus direct tronc tel jeans ante endebl caract situacion min dud desabroch boton separ lujuri plac tangibl corri rop tom tronc fierez determinacion sac pech rap movimient mientr palabr concis brot instint hermos pij ten titub baj rodill suel adopt posicion sumis mir haci arrib pid permis empun haci boc blanque ojos dej hac sabi pas lengu contorn larg miembr lubric saliv mientr humed tom juguet pezon ros pellizc masaj acompan movimient tiemp levant braz fuerz gir ella apoy palm abiert par acarici mientr encorv espald facund man derech desprend boton pantalon min termin baj plieg sep col piern mientr antebraz izquierd haci presion espald alta asegur mov intent alej hic agarr tronc busc glute perfect redond puert entrad extasis gem mezcl dolor sorpres sali boc sosteni cintur hiz carg cad movimient podi leer cuerp pedi grit sabi hac lleg punt mujer vuelv loc mordi cuell deton moment final contraccion cuerp min incendi facu e...  \n",
       "7  moment mariel alej sient oid etern esper instant cierr ojos sient man met disimul abaj fald abro encuentr esper secret hac present trat evident mir irresist camis negr plen pantalon jean ajust barb recort perfeccion pel rubi oscur cort acomod dese hac present conoc fiest quier piens acerc mariel present amig hac mir leon pres expect moment alej pront vendr nuev llen gent alej mes empiez bail bail junt temperatur empiez aument bes vien bes veng dig ban camin ban man agarr llev ban discapacit grand cierr puert pon trab hund cuell sab calient sab ambos jadeant dese animal salvaj actu sol instint baj fald desprend pantalon denot ereccion crecient baj box hund ansi boc sex prueb disfrut despu instant levant pon man par sient plac hund cuerp incont vec gem extasis inconmesur ven des hac met man escot dars impuls plac constant cuant tiemp pas frenesi acab fund bes apasion import acomod rop pel haci mism destrab puert ban encontr mariel cre sospech alcohol encim dij event termin genial ami...  \n",
       "8  televisor sabi hac cam dij mir hac cam probabl termin durm dij sonr desafi hic sof qued cam plaz recost lad gan pon pelicul cre ment pas mism bes boc pas segu obvi pareci habi empez cam casi bes aument mord suav labi rop cayend cost sof dandom cuent rot noch tambi necesit calor cuand desnud qued subi arrib plac sex suav lent mientr cabalg man recorr piel pech mientr corri pel larg tap car cuant tiemp pas extasis agot lad mir sup inmediat segu baj lent sex zambull profund dandom plac lengu ded gemi plac haci tiemp senti clav unas hombr extasi plac pront senti aquell fueg artificial caracteriz orgasm cuent levant suavement volvi bes intens boc habl palabr tampoc hiz falt ahor domin situacion subi nuev arrib llev miembr boc sabor mientr vei cerr ojos extasi volvi cabalg senti lleg orgasm recost mir ojos reim reim bes nuev reim qued post extasis cuant tiemp tampoc import despu empez busc rop vest prendi cigarrill cuand termin bes boc susurr cab cuatr manan abri puert volv bes irse sup ...  \n",
       "9  look llam atencion cun salon viend tel pus junt agach cog objet habi suel podri dec pus nalg delant car cuand levant mir dirigi sonris maner darl verd jug conmig bien accion pareci habi paraliz fond sabi habi encant repent mir direct ojos autent lob cel dij dic gust balbuc dij muj precios novi herman bastant dij buen vam famili seri ideal conocier cre dirigi mir direct paquet pon bien dur soldadit bastant inquiet dej mir cun qued inmoviliz acerqu desabroch pantalon qued sol slips paquet descomunal empec toc guarr encant hac dij cun cun med masturb empez bes cuell mientr cogi fuertement pech segui masturb moment dad pus ofreci con bien humed saci buen perrit lamedor empez chup form increibl bien haci puneter queri par volv total loc segu lleg orgasm habi premi esmer chic dispus com miembr fond arrib abaj dentr corri ensegu menud tronc ties teni comi jug saladit extraordinari cun total entreg pies bastant excit pus cuatr pat darm unas buen acomet cos descomunal hac guarr nunc pen ent...  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 1000)\n",
    "table = pd.DataFrame(phrases,columns=['score','Phrase'])\n",
    "table = table.sort_values('score',ascending=False)\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
